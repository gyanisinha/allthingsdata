{"cells":[{"cell_type":"markdown","source":["# Large XML processing in Fabric using spark-xml\n","- Here is what you can do for processing large xml:\n","    - Create new environment and upload custom library. Maven Repository: com.databricks » spark-xml_2.12 » 0.18.0. (spark-xml_2.12-0.18.0.jar). Save and publish.\n","    - Read using pyspark"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"273385be-0a85-433c-8b0f-0f7e5002ab5c"},{"cell_type":"code","source":["df = spark.read.format(\"com.databricks.spark.xml\").option(\"rowTag\", \"dataset\").(load(\"Files/xml/example.xml\")\n","df.printSchema()\n","# Show the DataFrame (optional)\n","df.show()\n","# Write the DataFrame to Parquet format or any other format as needed\n","df.write.parquet(\"Files/processed/example.parquet\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"abd4c3cf-b6c2-4256-9825-2c9a1ccb0024"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}